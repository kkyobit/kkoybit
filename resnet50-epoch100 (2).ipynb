{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchmetrics timm\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import datasets, models, transforms\nimport torch\nfrom matplotlib import pyplot as plt\nfrom tensorflow import keras\nfrom cv2 import imread\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten\nfrom tensorflow.keras.layers import Dropout, BatchNormalization \nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nimport torchmetrics \nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch import nn\nfrom torch.optim import AdamW,Adam # optmizers\nimport time\nfrom keras.callbacks import ModelCheckpoint\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nimport os\nimport glob\nimport plotly.graph_objects as go\nimport cv2\nfrom PIL import Image\nfrom PIL import ImageFile\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nfrom tqdm import tqdm","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터","metadata":{}},{"cell_type":"code","source":"# save csv (files_df)\n#files_df.to_csv('/kaggle/working/dropfiles.csv', sep=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 정리된 files_df 사용\n#files_df = pd.read_csv('../input/dropfiles/dropfiles.csv', sep=',').drop('Unnamed: 0', axis=1)\n#files_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 분리","metadata":{}},{"cell_type":"code","source":"X_valid = np.load('../input/cervical-cancer-screening128/X_valid_128.npy',allow_pickle=True)\ny_valid = np.load('../input/cervical-cancer-screening128/y_valid_128.npy',allow_pickle=True)\nX_train = np.load('../input/cervical-cancer-screening128/X_train_128.npy',allow_pickle=True)\ny_train = np.load('../input/cervical-cancer-screening128/y_train_128.npy',allow_pickle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 전처리","metadata":{}},{"cell_type":"code","source":"# save train data as npy files\n\n#np.save('/kaggle/working/X_train_25', X_train)\n#np.save('/kaggle/working/y_train_25', y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 소요시간줄이는코드 (추가 수정 필요)\n#path = train_df['filepath'].values\n#labels = train_df['label'].values\n#features = [np.array(cv2.resize(cv2.cvtColor(cv2.imread(p),cv2.COLOR_RGB2BGR),(180,180))) for p in tqdm(path)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save validation data as npy files\n\n#np.save('/kaggle/working/X_valid', X_valid)\n#np.save('/kaggle/working/y_valid', y_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X train data 확인\nX_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X validation data 확인\nX_valid[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 정규화 (0과1사이의값)\nX_train = X_train/255\nX_valid = X_valid/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 정규화한 X train data 확인\nX_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 정규화한 X validation data 확인\nX_valid[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train 개수, 차원 확인\nprint(len(X_train), len(y_train))\nprint(X_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation 개수, 차원 확인\nprint(len(X_valid), len(y_valid))\nprint(X_valid.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y 라벨링 (string -> int)\nle = LabelEncoder().fit(['Type 1', 'Type 2', 'Type 3'])\ny_train = le.transform(y_train)\ny_valid = le.transform(y_valid)\n\ny_train_onehot = to_categorical(y_train, num_classes=3)\ny_valid_onehot = to_categorical(y_valid, num_classes=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_onehot[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid_onehot[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n\n\nclass conv_block(tf.keras.Model):\n    def __init__(self, filters, strides=(2, 2)):\n        super(conv_block, self).__init__()\n\n        self.filters1, self.filters2, self.filters3 = filters\n        self.strides = strides\n\n        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=strides)\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.relu1 = tf.keras.layers.ReLU()\n\n        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.relu2 = tf.keras.layers.ReLU()\n\n        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))\n        self.bn3 = tf.keras.layers.BatchNormalization()\n\n        self.shortcut_conv = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=strides)\n        self.shortcut_bn = tf.keras.layers.BatchNormalization()\n\n        self.add = tf.keras.layers.Add()\n        self.add_relu = tf.keras.layers.ReLU()\n\n\n    def call(self, input_tensor, training=False):\n        x = self.conv1(input_tensor)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        shortcut = self.shortcut_conv(input_tensor)\n        shortcut = self.shortcut_bn(shortcut)\n\n        x = self.add([x, shortcut])\n        x = self.add_relu(x)\n\n        return x\n        \n\n\nclass identity_block(tf.keras.Model):\n    def __init__(self, filters):\n        super(identity_block, self).__init__()\n\n        self.filters1, self.filters2, self.filters3 = filters\n\n        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=(1, 1))\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.relu1 = tf.keras.layers.ReLU()\n\n        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.relu2 = tf.keras.layers.ReLU()\n\n        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        \n        self.add = tf.keras.layers.Add()\n        self.add_relu = tf.keras.layers.ReLU()\n\n    \n    def call(self, input_tensor, training=False):\n        x = self.conv1(input_tensor)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        x = self.add([x, input_tensor])\n        x = self.add_relu(x)\n\n        return x\n\n\n\n\n    \nclass ResNet50(tf.keras.Model):\n    def __init__(self, nb_classes):\n        super(ResNet50, self).__init__()\n\n        self.nb_classes = nb_classes\n\n        # Stage 1 (Conv1 Layer)\n        self.zero_padd_1_1 = tf.keras.layers.ZeroPadding2D(padding=(3, 3))\n        self.conv_1 = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2))\n        self.bn_1 = tf.keras.layers.BatchNormalization()\n        self.relu_1 = tf.keras.layers.ReLU()\n        self.zero_padd_1_2 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))\n        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))\n\n        # Stage 2\n        self.stage2 = tf.keras.Sequential()\n        self.stage2.add(conv_block([64, 64, 256], strides=(1, 1)))\n        self.stage2.add(identity_block([64, 64, 256]))\n        self.stage2.add(identity_block([64, 64, 256]))\n\n        # Stage 3\n        self.stage3 = tf.keras.Sequential()\n        self.stage3.add(conv_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n\n        # Stage 4\n        self.stage4 = tf.keras.Sequential()\n        self.stage4.add(conv_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n\n        # Stage 5\n        self.stage5 = tf.keras.Sequential()\n        self.stage5.add(conv_block([512, 512, 2048]))\n        self.stage5.add(identity_block([512, 512, 2048]))\n        self.stage5.add(identity_block([512, 512, 2048]))\n\n\n        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n        self.dense = tf.keras.layers.Dense(self.nb_classes, activation='softmax')\n\n\n    def call(self, input_tensor, training=False):\n        x = self.zero_padd_1_1(input_tensor)\n        x = self.conv_1(x)\n        x = self.bn_1(x)\n        x = self.relu_1(x)\n        x = self.zero_padd_1_2(x)\n        x = self.max_pool(x)\n\n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.stage4(x)\n        x = self.stage5(x)\n\n        x = self.gap(x)\n        x = self.dense(x)\n\n        return x \n\n\nmodel = ResNet50(1000)\nmodel.build((1, 128, 128, 3))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    loss = 'sparse_categorical_crossentropy'\n    ,metrics = ['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nTRAIN_STEPS = len(X_train)//BATCH_SIZE\nVAL_STEPS = len(X_valid)//BATCH_SIZE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255,\n                     rotation_range=20,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.1,\n                     vertical_flip=True,\n                     horizontal_flip=True,\n                     fill_mode='nearest')\n\n\ntrain_gen = train_datagen.flow(X_train, y_train, batch_size = BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduceLR = ReduceLROnPlateau(monitor='val_accuracy', patience=10, verbose= 1, mode='max', factor=  0.2, min_lr = 1e-5)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience = 20, verbose=1, mode='max', restore_best_weights= True)\n\ncheckpoint = ModelCheckpoint('ResNet50', monitor='val_accuracy', verbose=1,save_best_only=True, mode= 'max')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Non-augmentation\ntrain_gen = ImageDataGenerator().flow(X_train, y_train, batch_size = BATCH_SIZE)\nvalid_gen = ImageDataGenerator().flow(X_valid, y_valid, batch_size = BATCH_SIZE)\n\nhistory_res50 = model.fit(\n    train_gen\n    , steps_per_epoch= TRAIN_STEPS\n    , validation_data= valid_gen\n    , validation_steps=VAL_STEPS\n    , epochs= 100\n    , callbacks= [reduceLR, early_stopping, checkpoint]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history_res50.history['accuracy'], label='Training Accuracy')\nplt.plot(history_res50.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history_res50.history['loss'], label='Training Loss')\nplt.plot(history_res50.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n\n\nclass conv_block(tf.keras.Model):\n    def __init__(self, filters, strides=(2, 2)):\n        super(conv_block, self).__init__()\n\n        self.filters1, self.filters2, self.filters3 = filters\n        self.strides = strides\n\n        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=strides)\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.relu1 = tf.keras.layers.ReLU()\n\n        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.relu2 = tf.keras.layers.ReLU()\n\n        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))\n        self.bn3 = tf.keras.layers.BatchNormalization()\n\n        self.shortcut_conv = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=strides)\n        self.shortcut_bn = tf.keras.layers.BatchNormalization()\n\n        self.add = tf.keras.layers.Add()\n        self.add_relu = tf.keras.layers.ReLU()\n\n\n    def call(self, input_tensor, training=False):\n        x = self.conv1(input_tensor)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        shortcut = self.shortcut_conv(input_tensor)\n        shortcut = self.shortcut_bn(shortcut)\n\n        x = self.add([x, shortcut])\n        x = self.add_relu(x)\n\n        return x\n        \n\n\nclass identity_block(tf.keras.Model):\n    def __init__(self, filters):\n        super(identity_block, self).__init__()\n\n        self.filters1, self.filters2, self.filters3 = filters\n\n        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=(1, 1))\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.relu1 = tf.keras.layers.ReLU()\n\n        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.relu2 = tf.keras.layers.ReLU()\n\n        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        \n        self.add = tf.keras.layers.Add()\n        self.add_relu = tf.keras.layers.ReLU()\n\n    \n    def call(self, input_tensor, training=False):\n        x = self.conv1(input_tensor)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        x = self.add([x, input_tensor])\n        x = self.add_relu(x)\n\n        return x\n\n\n\n\n    \nclass ResNet50(tf.keras.Model):\n    def __init__(self, nb_classes):\n        super(ResNet50, self).__init__()\n\n        self.nb_classes = nb_classes\n\n        # Stage 1 (Conv1 Layer)\n        self.zero_padd_1_1 = tf.keras.layers.ZeroPadding2D(padding=(3, 3))\n        self.conv_1 = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2))\n        self.bn_1 = tf.keras.layers.BatchNormalization()\n        self.relu_1 = tf.keras.layers.ReLU()\n        self.zero_padd_1_2 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))\n        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))\n\n        # Stage 2\n        self.stage2 = tf.keras.Sequential()\n        self.stage2.add(conv_block([64, 64, 256], strides=(1, 1)))\n        self.stage2.add(identity_block([64, 64, 256]))\n        self.stage2.add(identity_block([64, 64, 256]))\n\n        # Stage 3\n        self.stage3 = tf.keras.Sequential()\n        self.stage3.add(conv_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n\n        # Stage 4\n        self.stage4 = tf.keras.Sequential()\n        self.stage4.add(conv_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n\n        # Stage 5\n        self.stage5 = tf.keras.Sequential()\n        self.stage5.add(conv_block([512, 512, 2048]))\n        self.stage5.add(identity_block([512, 512, 2048]))\n        self.stage5.add(identity_block([512, 512, 2048]))\n\n\n        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n        self.dense = tf.keras.layers.Dense(self.nb_classes, activation='softmax')\n\n\n    def call(self, input_tensor, training=False):\n        x = self.zero_padd_1_1(input_tensor)\n        x = self.conv_1(x)\n        x = self.bn_1(x)\n        x = self.relu_1(x)\n        x = self.zero_padd_1_2(x)\n        x = self.max_pool(x)\n\n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.stage4(x)\n        x = self.stage5(x)\n\n        x = self.gap(x)\n        x = self.dense(x)\n\n        return x \n\n\nmodel_ag = ResNet50(1000)\nmodel_ag.build((1, 128, 128, 3))\nmodel_ag.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ag.compile(\n    loss = 'sparse_categorical_crossentropy'\n    ,metrics = ['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255,\n                     rotation_range=20,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.1,\n                     vertical_flip=True,\n                     horizontal_flip=True,\n                     fill_mode='nearest')\n\n\ntrain_gen_ag = train_datagen.flow(X_train, y_train, batch_size = BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduceLR = ReduceLROnPlateau(monitor='val_accuracy', patience=10, verbose= 1, mode='max', factor=  0.2, min_lr = 1e-5)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience = 20, verbose=1, mode='max', restore_best_weights= True)\n\ncheckpoint_ag = ModelCheckpoint('ResNet50_ag', monitor='val_accuracy', verbose=1,save_best_only=True, mode= 'max')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_res50_ag = model_ag.fit(\n    train_gen_ag\n    , steps_per_epoch= TRAIN_STEPS\n    , validation_data=valid_gen\n    , validation_steps=VAL_STEPS\n    , epochs= 100\n    , callbacks= [reduceLR, early_stopping, checkpoint_ag]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 16))\n\nplt.subplot(2, 2, 1)\nplt.plot(history_res50.history['accuracy'], label='Training Accuracy')\nplt.plot(history_res50.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Non-Augmentation Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(history_res50.history['loss'], label='Training Loss')\nplt.plot(history_res50.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Non-Augmentation Training and Validation Loss')\n\nplt.subplot(2, 2, 3)\nplt.plot(history_res50_ag.history['accuracy'], label='Training Accuracy')\nplt.plot(history_res50_ag.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Augmentation Training and Validation Accuracy')\n\nplt.subplot(2, 2, 4)\nplt.plot(history_res50_ag.history['loss'], label='Training Loss')\nplt.plot(history_res50_ag.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Augmentation Training and Validation Loss')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_enc = model.predict(X_valid)          # one-hot encoding된 label 예측값\ny_pred = [np.argmax(i) for i in y_pred_enc] # label 예측값\n\nitem = {\n      0: 'Type 1'\n    , 1: 'Type 2'\n    , 2: 'Type 3'\n}\n\nmatrix = confusion_matrix(y_valid, y_pred)\ndf = pd.DataFrame(matrix)\ndf.columns = item.values()\ndf.index = item.values()\n        \ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_enc = model_ag.predict(X_valid)          # one-hot encoding된 label 예측값\ny_pred = [np.argmax(i) for i in y_pred_enc] # label 예측값\n\nitem = {\n      0: 'Type 1'\n    , 1: 'Type 2'\n    , 2: 'Type 3'\n}\n\nmatrix = confusion_matrix(y_valid, y_pred)\ndf = pd.DataFrame(matrix)\ndf.columns = item.values()\ndf.index = item.values()\n        \ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#이미지 오류남\n\n#stage1 = y_train[y_train == 0].index\n#stage2 = y_train[y_train == 1].index\n#stage3 = y_train[y_train == 2].index\n\n#\n\n#stage1 = np.where(y_train == 0)\n#type(stage1)\n#stageq = stage1[0]\n\n#stage2 = np.where(y_train == 1)\n#type(stage2)\n#stagew = stage2[0]\n\n#stage3 = np.where(y_train == 2)\n#type(stage3)\n#stagee = stage3[0]\n\n#\n\n#plt.figure(figsize=(20, 20))\n\n#for i in range(16):\n#    plt.subplot(4, 4, i+1)\n#    plt.suptitle('Type1 Images', fontsize=20) # 하나의 큰 제목 설정\n#    plt.imshow(X_train[stageq[i]])\n#    plt.title('Type1')\n#    plt.subplots_adjust(hspace=0.5)\n#    plt.axis(False)\n#plt.show()\n\n#\n\n#plt.figure(figsize=(20, 20))\n\n#for i in range(16):\n#    plt.subplot(4, 4, i+1)\n#    plt.suptitle('type2 Images', fontsize=20) # 하나의 큰 제목 설정\n#    plt.imshow(X_train[stagew[i]])\n#    plt.title('type2')\n#    plt.subplots_adjust(hspace=0.5)\n#    plt.axis(False)\n#plt.savefig('type2.png', dpi=300)\n#plt.show()\n\n#\n\n#plt.figure(figsize=(20, 20))\n#\n#for i in range(16):\n#    plt.subplot(4, 4, i+1)\n#    plt.suptitle('type3 Images', fontsize=20) # 하나의 큰 제목 설정\n#    plt.imshow(X_train[stagee[i]])\n#    plt.title('type3')\n#    plt.subplots_adjust(hspace=0.5)\n#    plt.axis(False)\n#plt.savefig('type3.png', dpi=300)\n#plt.show()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 참고용\n# double\n\n#history_df_cnn = pd.DataFrame(historycnn.history)\n#history_df_dnn = pd.DataFrame(historydnn.history)\n\n#plt.figure(figsize= (15,6))\n#plt.subplot(1,2,1)\n#plt.plot(history_df_cnn['accuracy'], label= 'cnn_accuracy' )\n## plt.plot(history_df_cnn['val_accuracy'], label= 'val_accuracy')\n#plt.plot(history_df_dnn['accuracy'], label= 'dnn_accuracy', color='limegreen' )\n## plt.plot(history_df_dnn['val_accuracy'], label= 'val_accuracy', color='limegreen')\n## history_df[['acc', 'val_acc']]\n#plt.xlabel('Epochs')\n#plt.ylabel('Accuracy')\n#plt.title('Training and Validation Accuracy History')\n#plt.legend()\n\n# display history of loss\n#plt.subplot(1,2,2)\n#plt.plot(history_df_cnn['loss'], label= 'cnn_loss')\n##plt.plot(history_df_cnn['val_loss'], label= 'val_loss')\n#plt.plot(history_df_dnn['loss'], label= 'dnn_loss', color='limegreen')\n##plt.plot(history_df_dnn['val_loss'], label= 'val_loss', color='limegreen')\n# history_df[['loss', 'val_loss']].plot()\n#plt.xlabel('Epochs')\n#plt.ylabel('Loss')\n#plt.title('Training and Validation Loss History')\n#plt.legend()\n#plt.savefig('fig2.png', dpi=300)\n#plt.show()\n","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize= (6,6))\n#plt.plot(history_df_cnn['accuracy'], label= 'cnn_accuracy' )\n##plt.plot(history_df_cnn['val_loss'], label= 'val_loss')\n##plt.plot(history_df_dnn['loss'], label= 'dnn_loss', color='limegreen')\n##plt.plot(history_df_dnn['val_loss'], label= 'val_loss', color='limegreen')\n## history_df[['loss', 'val_loss']].plot()\n#plt.xlabel('Epochs')\n#plt.ylabel('Loss')\n#plt.title('Training and Validation Loss History')\n#plt.legend()\n#plt.savefig('cnnaccuracy.png', dpi=300)\n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test data (2차에 활용)","metadata":{}},{"cell_type":"code","source":"# test data\n\n#test_y = pd.read_csv(\"../input/intel-mobileodt-cervical-cancer-screening/solution_stg1_release.csv\")\n#test_y.loc[1,['Type_1','Type_2','Type_3']]\n\n#root_dir = '../input/intel-mobileodt-cervical-cancer-screening'\n#test_dir = os.path.join(root_dir,'test', 'test')\n\n#test_type = []\n#test_features = []\n#i=0\n#for fn in test_y[['image_name']].to_numpy():\n#    for filename in fn:\n#        filepath = os.path.join(test_dir,filename)\n#        #print(filepath)\n#        img = cv2.imread(filepath)\n#        resized_img = cv2.resize(img, (180, 180))\n#        test_features.append(np.array(resized_img))\n#        test_type.append(np.array(test_y.loc[i,['Type_1','Type_2','Type_3']]))\n#        i=i+1\n    \n#print( len(test_features))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_y = pd.read_csv(\"../input/intel-mobileodt-cervical-cancer-screening/solution_stg1_release.csv\")\n#test_y.loc[1,['Type_1','Type_2','Type_3']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test = test_y.loc[:,['Type_1','Type_2','Type_3']]\n#y_test\n#import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_train_onehot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(y_test)\n#list = []\n#for d in y_test.index:\n#    res = y_test.loc[d,:].values.tolist()\n#    list.append(res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test = np.array(list)\n#y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize test features\n#test_X = np.array(test_features)\n#X_test = test_X/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(cnn.evaluate(X_test, y_test))\n#print(dnn.evaluate(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}