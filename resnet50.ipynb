{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchmetrics timm\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import datasets, models, transforms\nimport torch\nfrom matplotlib import pyplot as plt\nfrom tensorflow import keras\nfrom cv2 import imread\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten\nfrom tensorflow.keras.layers import Dropout, BatchNormalization \nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nimport torchmetrics \nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch import nn\nfrom torch.optim import AdamW,Adam # optmizers\nimport time\nfrom keras.callbacks import ModelCheckpoint\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nimport os\nimport glob\nimport plotly.graph_objects as go\nimport cv2\nfrom PIL import Image\nfrom PIL import ImageFile\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nfrom tqdm import tqdm","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-22T04:05:41.524138Z","iopub.execute_input":"2022-11-22T04:05:41.524841Z","iopub.status.idle":"2022-11-22T04:06:05.525926Z","shell.execute_reply.started":"2022-11-22T04:05:41.524759Z","shell.execute_reply":"2022-11-22T04:06:05.523843Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.10.0)\nCollecting timm\n  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.21.6)\nRequirement already satisfied: torch>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.11.0+cpu)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (4.4.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0+cpu)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.64.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.7.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.13.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torchmetrics) (3.0.9)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.9.24)\nInstalling collected packages: timm\nSuccessfully installed timm-0.6.11\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# 데이터","metadata":{}},{"cell_type":"code","source":"label = pd.read_csv(\"../input/intel-mobileodt-cervical-cancer-screening/fixed_labels_v2.csv\")\nlabel","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:06:05.528379Z","iopub.execute_input":"2022-11-22T04:06:05.529345Z","iopub.status.idle":"2022-11-22T04:06:05.588791Z","shell.execute_reply.started":"2022-11-22T04:06:05.529305Z","shell.execute_reply":"2022-11-22T04:06:05.587428Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"      filename old_label new_label\n0       10.jpg    Type_2    Type_1\n1     1001.jpg    Type_2    Type_1\n2     1002.jpg    Type_3    Type_2\n3     1004.jpg    Type_2    Type_1\n4     1005.jpg    Type_3    Type_1\n...        ...       ...       ...\n1816   975.jpg    Type_2    Type_1\n1817   984.jpg    Type_2    Type_3\n1818   986.jpg    Type_2    Type_1\n1819   988.jpg    Type_2    Type_1\n1820   997.jpg    Type_3    Type_2\n\n[1821 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>old_label</th>\n      <th>new_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.jpg</td>\n      <td>Type_2</td>\n      <td>Type_1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001.jpg</td>\n      <td>Type_2</td>\n      <td>Type_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1002.jpg</td>\n      <td>Type_3</td>\n      <td>Type_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004.jpg</td>\n      <td>Type_2</td>\n      <td>Type_1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005.jpg</td>\n      <td>Type_3</td>\n      <td>Type_1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1816</th>\n      <td>975.jpg</td>\n      <td>Type_2</td>\n      <td>Type_1</td>\n    </tr>\n    <tr>\n      <th>1817</th>\n      <td>984.jpg</td>\n      <td>Type_2</td>\n      <td>Type_3</td>\n    </tr>\n    <tr>\n      <th>1818</th>\n      <td>986.jpg</td>\n      <td>Type_2</td>\n      <td>Type_1</td>\n    </tr>\n    <tr>\n      <th>1819</th>\n      <td>988.jpg</td>\n      <td>Type_2</td>\n      <td>Type_1</td>\n    </tr>\n    <tr>\n      <th>1820</th>\n      <td>997.jpg</td>\n      <td>Type_3</td>\n      <td>Type_2</td>\n    </tr>\n  </tbody>\n</table>\n<p>1821 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"root_dir = '../input/intel-mobileodt-cervical-cancer-screening'\ntrain_dir = os.path.join(root_dir,'train', 'train')\n\ntype1_dir = os.path.join(train_dir, 'Type_1')\ntype2_dir = os.path.join(train_dir, 'Type_2')\ntype3_dir = os.path.join(train_dir, 'Type_3')\n\ntrain_type1_files = glob.glob(type1_dir+'/*.jpg')\ntrain_type2_files = glob.glob(type2_dir+'/*.jpg')\ntrain_type3_files = glob.glob(type3_dir+'/*.jpg')\n\nadded_type1_files  =  glob.glob(os.path.join(root_dir, \"additional_Type_1_v2\", \"Type_1\")+'/*.jpg')\nadded_type2_files  =  glob.glob(os.path.join(root_dir, \"additional_Type_2_v2\", \"Type_2\")+'/*.jpg')\nadded_type3_files  =  glob.glob(os.path.join(root_dir, \"additional_Type_3_v2\", \"Type_3\")+'/*.jpg')\n\n\ntype1_files = train_type1_files + added_type1_files\ntype2_files = train_type2_files + added_type2_files\ntype3_files = train_type3_files + added_type3_files\n\nprint(f'''Type 1 files for training: {len(type1_files)} \nType 2 files for training: {len(type2_files)}\nType 3 files for training: {len(type3_files)}''' )","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:06:05.590457Z","iopub.execute_input":"2022-11-22T04:06:05.590772Z","iopub.status.idle":"2022-11-22T04:06:06.272556Z","shell.execute_reply.started":"2022-11-22T04:06:05.590746Z","shell.execute_reply":"2022-11-22T04:06:06.271917Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Type 1 files for training: 1441 \nType 2 files for training: 4348\nType 3 files for training: 2426\n","output_type":"stream"}]},{"cell_type":"code","source":"files = {'filepath': type1_files + type2_files + type3_files,\n          'label': ['Type 1']* len(type1_files) + ['Type 2']* len(type2_files) + ['Type 3']* len(type3_files)}\n\nfiles_df = pd.DataFrame(files).sample(frac=1, random_state= 1).reset_index(drop=True)\nfiles_df","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:06:06.274486Z","iopub.execute_input":"2022-11-22T04:06:06.276035Z","iopub.status.idle":"2022-11-22T04:06:06.296308Z","shell.execute_reply.started":"2022-11-22T04:06:06.275964Z","shell.execute_reply":"2022-11-22T04:06:06.295583Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               filepath   label\n0     ../input/intel-mobileodt-cervical-cancer-scree...  Type 1\n1     ../input/intel-mobileodt-cervical-cancer-scree...  Type 3\n2     ../input/intel-mobileodt-cervical-cancer-scree...  Type 1\n3     ../input/intel-mobileodt-cervical-cancer-scree...  Type 2\n4     ../input/intel-mobileodt-cervical-cancer-scree...  Type 3\n...                                                 ...     ...\n8210  ../input/intel-mobileodt-cervical-cancer-scree...  Type 2\n8211  ../input/intel-mobileodt-cervical-cancer-scree...  Type 3\n8212  ../input/intel-mobileodt-cervical-cancer-scree...  Type 1\n8213  ../input/intel-mobileodt-cervical-cancer-scree...  Type 2\n8214  ../input/intel-mobileodt-cervical-cancer-scree...  Type 1\n\n[8215 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8210</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 2</td>\n    </tr>\n    <tr>\n      <th>8211</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 3</td>\n    </tr>\n    <tr>\n      <th>8212</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 1</td>\n    </tr>\n    <tr>\n      <th>8213</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 2</td>\n    </tr>\n    <tr>\n      <th>8214</th>\n      <td>../input/intel-mobileodt-cervical-cancer-scree...</td>\n      <td>Type 1</td>\n    </tr>\n  </tbody>\n</table>\n<p>8215 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"bad_files = []\nfor path in tqdm(files_df['filepath'].values):\n    try:\n        img = Image.open(path)\n    except:\n        index = files_df[files_df['filepath']==path].index.values[0]\n        bad_files.append(index)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:06:06.297379Z","iopub.execute_input":"2022-11-22T04:06:06.298119Z","iopub.status.idle":"2022-11-22T04:09:18.474925Z","shell.execute_reply.started":"2022-11-22T04:06:06.298093Z","shell.execute_reply":"2022-11-22T04:09:18.473428Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 8215/8215 [03:12<00:00, 42.75it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"bad_files\nfiles_df.drop(bad_files, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.478150Z","iopub.execute_input":"2022-11-22T04:09:18.478462Z","iopub.status.idle":"2022-11-22T04:09:18.486218Z","shell.execute_reply.started":"2022-11-22T04:09:18.478437Z","shell.execute_reply":"2022-11-22T04:09:18.484673Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# save csv (files_df)\n#files_df.to_csv('/kaggle/working/dropfiles.csv', sep=',')","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.488548Z","iopub.execute_input":"2022-11-22T04:09:18.488926Z","iopub.status.idle":"2022-11-22T04:09:18.499700Z","shell.execute_reply.started":"2022-11-22T04:09:18.488900Z","shell.execute_reply":"2022-11-22T04:09:18.498193Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 정리된 files_df 사용\n#files_df = pd.read_csv('../input/dropfiles/dropfiles.csv', sep=',').drop('Unnamed: 0', axis=1)\n#files_df","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.502845Z","iopub.execute_input":"2022-11-22T04:09:18.503226Z","iopub.status.idle":"2022-11-22T04:09:18.512518Z","shell.execute_reply.started":"2022-11-22T04:09:18.503202Z","shell.execute_reply":"2022-11-22T04:09:18.511304Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# get count of each type \ntype_count = pd.DataFrame(files_df['label'].value_counts()).rename(columns= {'label': 'Num_Values'})\ntype_count","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.515024Z","iopub.execute_input":"2022-11-22T04:09:18.515455Z","iopub.status.idle":"2022-11-22T04:09:18.538430Z","shell.execute_reply.started":"2022-11-22T04:09:18.515418Z","shell.execute_reply":"2022-11-22T04:09:18.537311Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        Num_Values\nType 2        4346\nType 3        2426\nType 1        1440","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Num_Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Type 2</th>\n      <td>4346</td>\n    </tr>\n    <tr>\n      <th>Type 3</th>\n      <td>2426</td>\n    </tr>\n    <tr>\n      <th>Type 1</th>\n      <td>1440</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"plt.figure(figsize = (15, 6))\nsns.barplot(x= type_count['Num_Values'], y= type_count.index.to_list())\nplt.title('Type Distribution')\nplt.grid(True)\nplt.show()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-11-22T04:09:18.543578Z","iopub.execute_input":"2022-11-22T04:09:18.544539Z","iopub.status.idle":"2022-11-22T04:09:18.703356Z","shell.execute_reply.started":"2022-11-22T04:09:18.544506Z","shell.execute_reply":"2022-11-22T04:09:18.702658Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x432 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA3oAAAGECAYAAABgVFI4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb7ElEQVR4nO3de7TvdV3n8ddbDsgtBQFRQcC7mA1YDqMj1sFKU1OmdBRHRQsjuzDZjMsuNIZSjY02ZqzSIQeFIMzQ0rSVGbjVYUySQAGRvOYFxQuCHuQi8J4/ft/jbLf7XPY+5/A7+8PjsdZZ5/e9/L7fz2/xUfaT7/f33dXdAQAAYBx3mfcAAAAA2L6EHgAAwGCEHgAAwGCEHgAAwGCEHgAAwGCEHgAAwGCEHgAsUVWHVNWGqtplOx3vdVX136bX66vq89vjuNPxHltVV22v4wEwBqEHwB1qCqiNf26vqhsXLT/7Djj/86vqtkXn/HRVvaGqHrxxn+7+bHfv3d23bcWx/s+WztndL+zuU7fT+LuqHrjo2O/v7odsj2MDMA6hB8Adagqovbt77ySfTfKURevOuYOG8YHp/HdP8mNJbkxycVU9fHufaHtdFQSAlRB6AMxdVe1WVddW1Q8sWnfPqvpWVR2w8XbHqvrNqvpqVX1m8dW/qrprVb2qqj5bVddMt0rusaXzdvdt3f3J7v7FJO9Ncsp0vMOmK2frpuXnV9Wnquqb0xXAZ1fV4Ulel+TR05XB66Z931hVr62qv62qG5IcM637nSWfeVOfZaGqXrBo+TtXDavqfdPqD0/nfObSW0Gr6vDpGNdV1RVV9dRF295YVX9cVe+cPssHq+oBW/4nBMBaI/QAmLvuviXJm5I8Z9HqZyU5v7u/Mi3fK8n+SQ5K8rwkp1fVxlsWX5HkwUmOTPLAaZ+XrnAYb03y2KUrq2qvJH+U5Ind/X1J/n2SS7v7yiQvzHR1sLv3WfS2/5Tkd5N8X5Llbu3c3GfZpO7+4enlEdM5/2LJWHdN8jdJ/j7JPZOclOScJcc+LsnLkuyb5BPTOAEYjNADYGdxZpJnVVVNy89N8mdL9vlv3X1zd783yTuTPGPa/8Qkv9rd13b3N5P8XmZBsxJXJ7nHJrbdnuThVbVHd3+xu6/YwrHe1t0Xdvft3X3TJvb5ns+ywvEu51FJ9k7yiu6+pbsvSPKOzKJ5o7/q7ou6+9Yk52QWxwAMRugBsFPo7g8m+VaS9VX10MyuzL190S5f7+4bFi3/a5L7JDkgyZ6ZfcfuuukWyr+b1q/EQUmuXWZcNyR5ZmZX77443fb40C0c63Nb2L6pz7Kt7pPkc919+5JjH7Ro+UuLXn8rszAEYDBCD4CdyZmZ3b753CTnLbkatu90G+VGh2R2Fe6rmT1M5fu7e5/pz92nh62sxE8lef9yG7r7Xd3940nuneRjSf5046ZNHGtT6zfa1GdJkhsyC9eN7rWFYy12dZL7VtXif78fkuQLKzgGAAMQegDsTM7OLLiek+SsZba/bHpwy2OT/GSSv5yuXv1pkldX1T2TpKoOqqonbOlkVbVLVd2vqk5Lsj6z764t3efAqjp2CrObk2zI7FbOJLkmycFVtdtKP+hyn2Vaf2mSn66qPadfo3DCkvddk+T+mzjmxquiL6mqXatqfZKnZPb9RwDuRIQeADuN7v5ckn/O7IrY0qtrX0ry9cyuWp2T5IXd/bFp269l9mCRf6yqbyT5hySbe7jJo6tqQ5JvJFlIcrck/7a7L1tm37sk+S/Tea9N8iNJfmHadkGSK5J8qaq+uvWfdLOf5dVJbsks6M6cti92SpIzp9tUv+t7fdNDbZ6S5ImZXen8kyTHLzo2AHcS1b2lu0sA4I5TVWckubq7f2vRuvVJzu7ug+c1LgBYS9bNewAAsFFVHZbkp5M8Ys5DAYA1za2bAOwUqurUJJcneWV3f3re4wGAtcytmwAAAINxRQ8AAGAwQg8AAGAwa/ZhLPvss08/8IEPnPcwYIe44YYbstdee215R1hjzG1GZn4zKnN753XxxRd/tbsPWG7bmg29Aw88MB/60IfmPQzYIRYWFrJ+/fp5DwO2O3ObkZnfjMrc3nlV1b9uaptbNwEAAAYj9AAAAAYj9AAAAAYj9AAAAAYj9AAAAAYj9AAAAAYj9AAAAAYj9AAAAAYj9AAAAAZT3T3vMazKofd/QO//tN+e9zBgh3jBEXvl9R++Yd7DgO3O3GZk5jejurPP7Ytfefy8h7BJVXVxdz9yuW2u6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxG6AEAAAxm3eY2VtV+Sc6fFu+V5LYkX5mWj+ruW7bHIKrqyCSvTXK36Ry/291/sT2ODQAAcGez2dDr7q8lOTJJquqUJBu6+1U7YBzfSnJ8d3+8qu6T5OKqeld3X7cDzgUAADC0ld66uUdVfbqqdk2SqrrbxuWqWqiq11TVpVV1eVUdNe2zV1WdUVUXVdUlVXXs0oN2979098en11cn+XKSA7bxswEAANwpbfaK3jJuTLKQ5MlJ/jrJcUne2t3frqok2bO7j6yqH05yRpKHJzk5yQXd/bNVtU+Si6rqH7r7huVOMAXibkk+ucy2E5OcmCT7739AXnDEXiscPqwN+++5i/nNkMxtRmZ+M6o7+9xeWFiY9xBWZaWhlySvT/KSzELvZ5L83KJt5yZJd79vutq3T5LHJ3lqVb142mf3JIckuXLpgavq3kn+LMnzuvv2pdu7+/QkpyfJofd/QL/+w8u2Iqx5Lzhir5jfjMjcZmTmN6O6s8/ti5/ztHkPYVVWHHrdfWFVHVZV65Ps0t2XL968dPckleRp3X3V5o5bVXdL8s4kJ3f3P650XAAAAMys9tcrnJXkz5O8Ycn6ZyZJVR2d5Pruvj7Ju5KcVNO9nVX1iKUHq6rdkvxVkrO6+7xVjgkAAICsPvTOSbJvpls1F7mpqi5J8rokJ0zrTk2ya5KPVNUV0/JSz0jyw0mePz3M5dLpVy4AAACwQlt962Z3n7Jo8egk5y3z6w/O7u4XLXnfjUl+fgvHPjvJ2Vs7FgAAADZtxd/Rq6rTkjwxyZO2/3AAAADYVqt5GMtJm1i/fptHAwAAwDZb7Xf0AAAA2EkJPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMEIPQAAgMFUd897DKvykIc8pK+66qp5DwN2iIWFhaxfv37ew4DtztxmZOY3ozK3d15VdXF3P3K5ba7oAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADEboAQAADGbdvAewWv3tm/LZl//AvIcBO8QtD/qFfPblJ817GLDdmdurc8hLL5v3EABYY1zRAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGIzQAwAAGMy6zW2sqv2SnD8t3ivJbUm+Mi0f1d23bI9BVNWhSf4qs/DcNclp3f267XFsAACAO5vNhl53fy3JkUlSVack2dDdr9oB4/hikkd3981VtXeSy6vq7d199Q44FwAAwNBWeuvmHlX16araNUmq6m4bl6tqoapeU1WXVtXlVXXUtM9eVXVGVV1UVZdU1bFLD9rdt3T3zdPiXVcxLgAAACYrDaobkywkefK0fFySt3b3t6flPbv7yCS/mOSMad3JSS7o7qOSHJPklVW119IDV9V9q+ojST6X5PddzQMAAFid6u6t23G6dTPJB5K8pLuPraoPJPm57r68qhaSvLy7L5j2/2ySf5PkH5LsnuTW6VD3SPKE7r5yE+e5T5K/TvKU7r5mybYTk5yYJAfsv/8Pnf1HL9v6TwpryE13PSC73/yVLe8Ia4y5vTq73fth8x4CW2HDhg3Ze++95z0M2O7M7Z3XMcccc3F3P3K5bZv9jt5yuvvCqjqsqtYn2aW7L1+8eenuSSrJ07r7qq08/tVVdXmSxyY5b8m205OcniQPvv+h/dCPv3alw4c14WMP+oWY34zI3F6dQ5512byHwFZYWFjI+vXr5z0M2O7M7bVptd+FOyvJnyd5w5L1z0ySqjo6yfXdfX2SdyU5qapq2vaIpQerqoOrao/p9b5Jjk6yVWEIAADAd1tt6J2TZN8k5y5Zf1NVXZLkdUlOmNadmtmvTPhIVV0xLS91eJIPVtWHk7w3yau623++BAAAWIWtvnWzu09ZtHh0kvO6+7olu53d3S9a8r4bk/z8Fo797sy+zwcAAMA2WvF39KrqtCRPTPKk7T8cAAAAttVqHsZy0ibWr9/m0QAAALDN/GJyAACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwayb9wBWq3bdPYe89LJ5DwN2iE8tLOSQZ5nfjMfcBoA7hit6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAgxF6AAAAg1k37wGs1k233pTHnPaYeQ8DdojjDzw+J5928ryHsaZdeNKF8x4CAMDcuKIHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwmM2GXlXtV1WXTn++VFVfWLS82/YcSFX9XVVdV1Xv2J7HBQAAuLNZt7mN3f21JEcmSVWdkmRDd79qB43llUn2TPLzO+j4AAAAdworvXVzj6r6dFXtmiRVdbeNy1W1UFWvma72XV5VR0377FVVZ1TVRVV1SVUdu9yBu/v8JN/cto8DAADASkPvxiQLSZ48LR+X5K3d/e1pec/uPjLJLyY5Y1p3cpILuvuoJMckeWVV7bUtgwYAAGDTNnvr5ia8PslLkvx1kp9J8nOLtp2bJN39vulq3z5JHp/kqVX14mmf3ZMckuTKlZ64qk5McmKS7H/A/jn+wONXMXzY+e23637m9zZaWFiY9xBYxoYNG/yzYVjmN6Myt9emFYded19YVYdV1foku3T35Ys3L909SSV5WndftepR/v9zn57k9CQ59AGH9lnXnLWth4Sd0vEHHh/ze9tc+IwL5z0ElrGwsJD169fPexiwQ5jfjMrcXptW++sVzkry50nesGT9M5Okqo5Ocn13X5/kXUlOqqqatj1ilecEAABgK6w29M5Jsm+mWzUXuamqLknyuiQnTOtOTbJrko9U1RXT8veoqvcn+cskP1pVn6+qJ6xybAAAAHdqW33rZnefsmjx6CTndfd1S3Y7u7tftOR9N2YrfmVCdz92a8cCAADApq34O3pVdVqSJyZ50vYfDgAAANtqNQ9jOWkT69dv82gAAADYZqv9jh4AAAA7KaEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwmHXzHsBq7b5u91x40oXzHgbsEAsLC7nwGeY3AACr44oeAADAYIQeAADAYIQeAADAYIQeAADAYIQeAADAYIQeAADAYIQeAADAYIQeAADAYIQeAADAYIQeAADAYKq75z2GVamqbya5at7jgB1k/yRfnfcgYAcwtxmZ+c2ozO2d16HdfcByG9bd0SPZjq7q7kfOexCwI1TVh8xvRmRuMzLzm1GZ22uTWzcBAAAGI/QAAAAGs5ZD7/R5DwB2IPObUZnbjMz8ZlTm9hq0Zh/GAgAAwPLW8hU9AAAAlrEmQ6+qfqKqrqqqT1TVr897PLAlVXVGVX25qi5ftO4eVfXuqvr49Pe+0/qqqj+a5vdHquoHF73nedP+H6+q583js8BiVXXfqnpPVX20qq6oql+Z1pvfrHlVtXtVXVRVH57m98um9ferqg9O8/gvqmq3af1dp+VPTNsPW3Ss35jWX1VVT5jTR4LvUlW7VNUlVfWOadncHsiaC72q2iXJHyd5YpKHJXlWVT1svqOCLXpjkp9Ysu7Xk5zf3Q9Kcv60nMzm9oOmPycmeW0y+8E5yW8n+XdJjkry2xt/eIY5ujXJf+3uhyV5VJJfmv4/2fxmBDcneVx3H5HkyCQ/UVWPSvL7SV7d3Q9M8vUkJ0z7n5Dk69P6V0/7ZfrfxHFJvj+zfxf8yfTzDMzbryS5ctGyuT2QNRd6mf0A8Inu/lR335LkTUmOnfOYYLO6+31Jrl2y+tgkZ06vz0zyHxatP6tn/jHJPlV17yRPSPLu7r62u7+e5N353niEO1R3f7G7/3l6/c3MfmA4KOY3A5jm6YZpcdfpTyd5XJLzpvVL5/fGeX9ekh+tqprWv6m7b+7uTyf5RGY/z8DcVNXBSZ6c5PXTcsXcHspaDL2Dknxu0fLnp3Ww1hzY3V+cXn8pyYHT603NcXOfndp0K88jknww5jeDmG5tuzTJlzP7DxCfTHJdd9867bJ4rn5nHk/br0+yX8xvdk5/mOQlSW6flveLuT2UtRh6MJyePf7WI3BZs6pq7yRvSfKi7v7G4m3mN2tZd9/W3UcmOTizKxUPne+IYNtV1U8m+XJ3XzzvsbDjrMXQ+0KS+y5aPnhaB2vNNdMta5n+/vK0flNz3Nxnp1RVu2YWeed091un1eY3Q+nu65K8J8mjM7vleN20afFc/c48nrbfPcnXYn6z83lMkqdW1Wcy+xrU45K8Jub2UNZi6P1TkgdNTwXaLbMvgL59zmOC1Xh7ko1PFnxekrctWn/89HTCRyW5froF7l1JHl9V+04PqXj8tA7mZvqOxv9OcmV3/89Fm8xv1ryqOqCq9ple75HkxzP7Hup7kjx92m3p/N4475+e5ILpivbbkxw3Pbnwfpk9jOiiO+RDwDK6+ze6++DuPiyzn6Uv6O5nx9weyrot77Jz6e5bq+qXM/sBYJckZ3T3FXMeFmxWVZ2bZH2S/avq85k9XfAVSd5cVSck+dckz5h2/9skT8rsC83fSvIzSdLd11bVqZn9x44keXl3L33AC9zRHpPkuUkum77HlCS/GfObMdw7yZnTUwTvkuTN3f2OqvpokjdV1e8kuSSz/9iR6e8/q6pPZPYAruOSpLuvqKo3J/loZk+q/aXuvu0O/iywNX4t5vYwahbjAAAAjGIt3roJAADAZgg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9AACAwQg9ANa8quqq+oNFyy+uqlN20Ll+pKo+sGTduqq6pqrus4n3rK+qd+yI8QDAcoQeACO4OclPV9X+d8C53p/k4Ko6dNG6H0tyRXdffQecHwC2SOgBMIJbk5ye5FeXbqiqN1bV0xctb5j+Xl9V762qt1XVp6rqFVX17Kq6qKouq6oHLHei7r49yZuTHLdo9XFJzq2qo6rqA1V1SVX936p6yDLjOaWqXrxo+fKqOmx6/Zzp/JdW1f+qql2mP2+c9rusqr7nMwLAUkIPgFH8cZJnV9XdV/CeI5K8MMnhSZ6b5MHdfVSS1yc5aTPvOzdT6FXVXZM8KclbknwsyWO7+xFJXprk97Z2IFV1eJJnJnlMdx+Z5LYkz05yZJKDuvvh3f0DSd6wgs8HwJ3UunkPAAC2h+7+RlWdleQ/J7lxK9/2T939xSSpqk8m+ftp/WVJjtnMuT5UVXtPV+wOT/LB7r62qu6b5MyqelCSTrLrCj7Cjyb5oST/VFVJskeSLyf5myT3r6rTkrxz0RgBYJOEHgAj+cMk/5zvvup1a6Y7WKrqLkl2W7Tt5kWvb1+0fHu2/O/IjVf1Dp9eJ8mpSd7T3T813Y65sMz7vjOeye7T35XkzO7+jaVvqKojkjwhs6uPz0jys1sYGwB3cm7dBGAY3X1tZt+fO2HR6s9kdqUsSZ6alV1l25xzkzwnyeOSvG1ad/ckX5heP38T7/tMkh9Mkqr6wST3m9afn+TpVXXPads9qurQ6QEzd+nutyT5rY3vBYDNEXoAjOYPkix++uafJvmRqvpwkkcnuWF7nKS7r5yOdUF3bzzm/0jy36vqkmz6iuBbktyjqq5I8stJ/mU63kczC7m/r6qPJHl3knsnOSjJQlVdmuTsJN9zxQ8AlqrunvcYAAAA2I5c0QMAABiMh7EAwCZU1clJ/uOS1X/Z3b87j/EAwNZy6yYAAMBg3LoJAAAwGKEHAAAwGKEHAAAwGKEHAAAwGKEHAAAwmP8HPuf5DWivCjAAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"pie_plot = go.Pie(labels= type_count.index.to_list(), values= type_count.values.flatten(),\n                 hole= 0.2, text= type_count.index.to_list(), textposition='auto')\nfig = go.Figure([pie_plot])\nfig.update_layout(title_text='Pie Chart of Type Distribution')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.704586Z","iopub.execute_input":"2022-11-22T04:09:18.704942Z","iopub.status.idle":"2022-11-22T04:09:18.836417Z","shell.execute_reply.started":"2022-11-22T04:09:18.704919Z","shell.execute_reply":"2022-11-22T04:09:18.835381Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"04c621b9-252c-447e-954d-eecc65a889a3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04c621b9-252c-447e-954d-eecc65a889a3\")) {                    Plotly.newPlot(                        \"04c621b9-252c-447e-954d-eecc65a889a3\",                        [{\"hole\":0.2,\"labels\":[\"Type 2\",\"Type 3\",\"Type 1\"],\"text\":[\"Type 2\",\"Type 3\",\"Type 1\"],\"textposition\":\"auto\",\"values\":[4346,2426,1440],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Pie Chart of Type Distribution\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('04c621b9-252c-447e-954d-eecc65a889a3');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 데이터 분리","metadata":{}},{"cell_type":"code","source":"# Train / Validation\n\ntrain_df, valid_df = train_test_split(files_df, test_size = 0.2, stratify = files_df['label'], random_state = 1234)\n\nprint(len(train_df), len(valid_df))","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.838099Z","iopub.execute_input":"2022-11-22T04:09:18.838355Z","iopub.status.idle":"2022-11-22T04:09:18.853645Z","shell.execute_reply.started":"2022-11-22T04:09:18.838330Z","shell.execute_reply":"2022-11-22T04:09:18.852169Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"6569 1643\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train = train_df[['filepath']]\ny_train = train_df[['label']]\nX_train = X_train.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.855607Z","iopub.execute_input":"2022-11-22T04:09:18.855979Z","iopub.status.idle":"2022-11-22T04:09:18.865584Z","shell.execute_reply.started":"2022-11-22T04:09:18.855943Z","shell.execute_reply":"2022-11-22T04:09:18.863847Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_valid = valid_df[['filepath']].reset_index(drop=True)\ny_valid = valid_df[['label']].reset_index(drop=True)\n\nprint(len(X_train), len(y_train), len(X_valid),len(y_valid))","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.867178Z","iopub.execute_input":"2022-11-22T04:09:18.867421Z","iopub.status.idle":"2022-11-22T04:09:18.878353Z","shell.execute_reply.started":"2022-11-22T04:09:18.867397Z","shell.execute_reply":"2022-11-22T04:09:18.876933Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"6569 6569 1643 1643\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 데이터 전처리","metadata":{}},{"cell_type":"code","source":"# save train data as npy files\n\n#np.save('/kaggle/working/X_train_25', X_train)\n#np.save('/kaggle/working/y_train_25', y_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.880350Z","iopub.execute_input":"2022-11-22T04:09:18.881087Z","iopub.status.idle":"2022-11-22T04:09:18.888329Z","shell.execute_reply.started":"2022-11-22T04:09:18.881051Z","shell.execute_reply":"2022-11-22T04:09:18.886957Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"features = []\nf_app = features.append\npath = train_df['filepath'].values\nlabels = train_df['label'].values\nfor p in tqdm(path):\n    image = cv2.imread(p)\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    re_image = cv2.resize(image, (224,224))\n    f_app(np.array(re_image))\n\nX_train = np.array(features)\ny_train = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:09:18.889836Z","iopub.execute_input":"2022-11-22T04:09:18.890229Z","iopub.status.idle":"2022-11-22T04:31:30.635035Z","shell.execute_reply.started":"2022-11-22T04:09:18.890196Z","shell.execute_reply":"2022-11-22T04:31:30.632649Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":" 23%|██▎       | 1503/6569 [05:01<19:10,  4.40it/s]Premature end of JPEG file\n 85%|████████▍ | 5581/6569 [18:49<02:52,  5.71it/s]Premature end of JPEG file\n100%|██████████| 6569/6569 [22:10<00:00,  4.94it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# 소요시간줄이는코드 (추가 수정 필요)\n#path = train_df['filepath'].values\n#labels = train_df['label'].values\n#features = [np.array(cv2.resize(cv2.cvtColor(cv2.imread(p),cv2.COLOR_RGB2BGR),(180,180))) for p in tqdm(path)]","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:31:30.638275Z","iopub.execute_input":"2022-11-22T04:31:30.638740Z","iopub.status.idle":"2022-11-22T04:31:30.647399Z","shell.execute_reply.started":"2022-11-22T04:31:30.638707Z","shell.execute_reply":"2022-11-22T04:31:30.645739Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# validation data\n\nfeatures = []\nf_app = features.append\npath = valid_df['filepath'].values\nlabels = valid_df['label'].values\nfor p in tqdm(path):\n    image = cv2.imread(p)\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    re_image = cv2.resize(image, (224,224))\n    f_app(np.array(re_image))\n\nX_valid = np.array(features)\ny_valid = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:31:30.649126Z","iopub.execute_input":"2022-11-22T04:31:30.649455Z","iopub.status.idle":"2022-11-22T04:36:53.674546Z","shell.execute_reply.started":"2022-11-22T04:31:30.649430Z","shell.execute_reply":"2022-11-22T04:36:53.672702Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":" 37%|███▋      | 615/1643 [02:06<03:29,  4.91it/s]Premature end of JPEG file\n100%|██████████| 1643/1643 [05:22<00:00,  5.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# save validation data as npy files\n\n#np.save('/kaggle/working/X_valid', X_valid)\n#np.save('/kaggle/working/y_valid', y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:36:53.676337Z","iopub.execute_input":"2022-11-22T04:36:53.676680Z","iopub.status.idle":"2022-11-22T04:36:53.682389Z","shell.execute_reply.started":"2022-11-22T04:36:53.676654Z","shell.execute_reply":"2022-11-22T04:36:53.680681Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# X train data 확인\nX_train[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:36:53.683815Z","iopub.execute_input":"2022-11-22T04:36:53.684137Z","iopub.status.idle":"2022-11-22T04:36:53.716412Z","shell.execute_reply.started":"2022-11-22T04:36:53.684109Z","shell.execute_reply":"2022-11-22T04:36:53.714522Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([[[ 64,  79,  86],\n        [ 72,  85,  93],\n        [ 70,  81,  87],\n        ...,\n        [ 90,  56,  81],\n        [ 84,  52,  75],\n        [ 91,  59,  83]],\n\n       [[ 69,  79,  86],\n        [ 78,  87,  92],\n        [ 81,  90,  97],\n        ...,\n        [ 93,  59,  84],\n        [ 92,  57,  82],\n        [ 90,  57,  80]],\n\n       [[ 76,  83,  93],\n        [ 79,  86,  94],\n        [ 85,  92,  98],\n        ...,\n        [ 97,  63,  90],\n        [ 94,  60,  87],\n        [ 92,  59,  85]],\n\n       ...,\n\n       [[111,  75, 101],\n        [109,  75, 102],\n        [ 92,  58,  85],\n        ...,\n        [ 62,  31,  46],\n        [ 62,  33,  51],\n        [ 71,  42,  62]],\n\n       [[120,  84, 110],\n        [109,  73, 101],\n        [ 99,  66,  92],\n        ...,\n        [ 60,  29,  45],\n        [ 69,  37,  59],\n        [ 74,  43,  69]],\n\n       [[124,  88, 114],\n        [117,  81, 107],\n        [110,  76, 101],\n        ...,\n        [ 68,  36,  57],\n        [ 81,  49,  73],\n        [ 84,  51,  80]]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"code","source":"# X validation data 확인\nX_valid[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:36:53.718401Z","iopub.execute_input":"2022-11-22T04:36:53.719359Z","iopub.status.idle":"2022-11-22T04:36:53.730524Z","shell.execute_reply.started":"2022-11-22T04:36:53.719318Z","shell.execute_reply":"2022-11-22T04:36:53.728737Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([[[ 53,  51,  68],\n        [ 56,  47,  67],\n        [ 55,  48,  64],\n        ...,\n        [ 22,  30,  37],\n        [ 22,  33,  39],\n        [ 30,  34,  43]],\n\n       [[ 59,  52,  71],\n        [ 61,  54,  72],\n        [ 59,  48,  67],\n        ...,\n        [ 25,  35,  44],\n        [ 24,  31,  42],\n        [ 28,  33,  44]],\n\n       [[ 64,  57,  74],\n        [ 61,  54,  72],\n        [ 67,  58,  77],\n        ...,\n        [ 29,  44,  51],\n        [ 27,  39,  47],\n        [ 24,  34,  43]],\n\n       ...,\n\n       [[ 65,  64,  84],\n        [ 77,  70,  93],\n        [ 93,  85, 109],\n        ...,\n        [ 53,  40,  57],\n        [ 50,  37,  54],\n        [ 51,  37,  55]],\n\n       [[ 53,  50,  71],\n        [ 64,  56,  79],\n        [ 70,  62,  85],\n        ...,\n        [ 54,  41,  61],\n        [ 49,  38,  55],\n        [ 48,  35,  52]],\n\n       [[ 40,  42,  62],\n        [ 51,  47,  68],\n        [ 60,  56,  77],\n        ...,\n        [ 49,  36,  56],\n        [ 49,  36,  56],\n        [ 48,  36,  52]]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"code","source":"# 정규화 (0과1사이의값)\nX_train = X_train/255\nX_valid = X_valid/255","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:36:53.732491Z","iopub.execute_input":"2022-11-22T04:36:53.732920Z","iopub.status.idle":"2022-11-22T04:37:04.489047Z","shell.execute_reply.started":"2022-11-22T04:36:53.732893Z","shell.execute_reply":"2022-11-22T04:37:04.487565Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# 정규화한 X train data 확인\nX_train[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.490691Z","iopub.execute_input":"2022-11-22T04:37:04.491089Z","iopub.status.idle":"2022-11-22T04:37:04.501794Z","shell.execute_reply.started":"2022-11-22T04:37:04.491045Z","shell.execute_reply":"2022-11-22T04:37:04.500678Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"array([[[0.25098039, 0.30980392, 0.3372549 ],\n        [0.28235294, 0.33333333, 0.36470588],\n        [0.2745098 , 0.31764706, 0.34117647],\n        ...,\n        [0.35294118, 0.21960784, 0.31764706],\n        [0.32941176, 0.20392157, 0.29411765],\n        [0.35686275, 0.23137255, 0.3254902 ]],\n\n       [[0.27058824, 0.30980392, 0.3372549 ],\n        [0.30588235, 0.34117647, 0.36078431],\n        [0.31764706, 0.35294118, 0.38039216],\n        ...,\n        [0.36470588, 0.23137255, 0.32941176],\n        [0.36078431, 0.22352941, 0.32156863],\n        [0.35294118, 0.22352941, 0.31372549]],\n\n       [[0.29803922, 0.3254902 , 0.36470588],\n        [0.30980392, 0.3372549 , 0.36862745],\n        [0.33333333, 0.36078431, 0.38431373],\n        ...,\n        [0.38039216, 0.24705882, 0.35294118],\n        [0.36862745, 0.23529412, 0.34117647],\n        [0.36078431, 0.23137255, 0.33333333]],\n\n       ...,\n\n       [[0.43529412, 0.29411765, 0.39607843],\n        [0.42745098, 0.29411765, 0.4       ],\n        [0.36078431, 0.22745098, 0.33333333],\n        ...,\n        [0.24313725, 0.12156863, 0.18039216],\n        [0.24313725, 0.12941176, 0.2       ],\n        [0.27843137, 0.16470588, 0.24313725]],\n\n       [[0.47058824, 0.32941176, 0.43137255],\n        [0.42745098, 0.28627451, 0.39607843],\n        [0.38823529, 0.25882353, 0.36078431],\n        ...,\n        [0.23529412, 0.11372549, 0.17647059],\n        [0.27058824, 0.14509804, 0.23137255],\n        [0.29019608, 0.16862745, 0.27058824]],\n\n       [[0.48627451, 0.34509804, 0.44705882],\n        [0.45882353, 0.31764706, 0.41960784],\n        [0.43137255, 0.29803922, 0.39607843],\n        ...,\n        [0.26666667, 0.14117647, 0.22352941],\n        [0.31764706, 0.19215686, 0.28627451],\n        [0.32941176, 0.2       , 0.31372549]]])"},"metadata":{}}]},{"cell_type":"code","source":"# 정규화한 X validation data 확인\nX_valid[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.503356Z","iopub.execute_input":"2022-11-22T04:37:04.504799Z","iopub.status.idle":"2022-11-22T04:37:04.516679Z","shell.execute_reply.started":"2022-11-22T04:37:04.504735Z","shell.execute_reply":"2022-11-22T04:37:04.514588Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([[[0.20784314, 0.2       , 0.26666667],\n        [0.21960784, 0.18431373, 0.2627451 ],\n        [0.21568627, 0.18823529, 0.25098039],\n        ...,\n        [0.08627451, 0.11764706, 0.14509804],\n        [0.08627451, 0.12941176, 0.15294118],\n        [0.11764706, 0.13333333, 0.16862745]],\n\n       [[0.23137255, 0.20392157, 0.27843137],\n        [0.23921569, 0.21176471, 0.28235294],\n        [0.23137255, 0.18823529, 0.2627451 ],\n        ...,\n        [0.09803922, 0.1372549 , 0.17254902],\n        [0.09411765, 0.12156863, 0.16470588],\n        [0.10980392, 0.12941176, 0.17254902]],\n\n       [[0.25098039, 0.22352941, 0.29019608],\n        [0.23921569, 0.21176471, 0.28235294],\n        [0.2627451 , 0.22745098, 0.30196078],\n        ...,\n        [0.11372549, 0.17254902, 0.2       ],\n        [0.10588235, 0.15294118, 0.18431373],\n        [0.09411765, 0.13333333, 0.16862745]],\n\n       ...,\n\n       [[0.25490196, 0.25098039, 0.32941176],\n        [0.30196078, 0.2745098 , 0.36470588],\n        [0.36470588, 0.33333333, 0.42745098],\n        ...,\n        [0.20784314, 0.15686275, 0.22352941],\n        [0.19607843, 0.14509804, 0.21176471],\n        [0.2       , 0.14509804, 0.21568627]],\n\n       [[0.20784314, 0.19607843, 0.27843137],\n        [0.25098039, 0.21960784, 0.30980392],\n        [0.2745098 , 0.24313725, 0.33333333],\n        ...,\n        [0.21176471, 0.16078431, 0.23921569],\n        [0.19215686, 0.14901961, 0.21568627],\n        [0.18823529, 0.1372549 , 0.20392157]],\n\n       [[0.15686275, 0.16470588, 0.24313725],\n        [0.2       , 0.18431373, 0.26666667],\n        [0.23529412, 0.21960784, 0.30196078],\n        ...,\n        [0.19215686, 0.14117647, 0.21960784],\n        [0.19215686, 0.14117647, 0.21960784],\n        [0.18823529, 0.14117647, 0.20392157]]])"},"metadata":{}}]},{"cell_type":"code","source":"# train 개수, 차원 확인\nprint(len(X_train), len(y_train))\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.518792Z","iopub.execute_input":"2022-11-22T04:37:04.519133Z","iopub.status.idle":"2022-11-22T04:37:04.529322Z","shell.execute_reply.started":"2022-11-22T04:37:04.519106Z","shell.execute_reply":"2022-11-22T04:37:04.527398Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"6569 6569\n(6569, 224, 224, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# validation 개수, 차원 확인\nprint(len(X_valid), len(y_valid))\nprint(X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.531403Z","iopub.execute_input":"2022-11-22T04:37:04.532681Z","iopub.status.idle":"2022-11-22T04:37:04.541307Z","shell.execute_reply.started":"2022-11-22T04:37:04.532606Z","shell.execute_reply":"2022-11-22T04:37:04.540279Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"1643 1643\n(1643, 224, 224, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# y 라벨링 (string -> int)\nle = LabelEncoder().fit(['Type 1', 'Type 2', 'Type 3'])\ny_train = le.transform(y_train)\ny_valid = le.transform(y_valid)\n\ny_train_onehot = to_categorical(y_train, num_classes=3)\ny_valid_onehot = to_categorical(y_valid, num_classes=3)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.542662Z","iopub.execute_input":"2022-11-22T04:37:04.543060Z","iopub.status.idle":"2022-11-22T04:37:04.557573Z","shell.execute_reply.started":"2022-11-22T04:37:04.543023Z","shell.execute_reply":"2022-11-22T04:37:04.556708Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"y_train_onehot[:5]","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.564903Z","iopub.execute_input":"2022-11-22T04:37:04.565754Z","iopub.status.idle":"2022-11-22T04:37:04.573043Z","shell.execute_reply.started":"2022-11-22T04:37:04.565726Z","shell.execute_reply":"2022-11-22T04:37:04.572181Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([[0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"y_valid_onehot[:5]","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.573998Z","iopub.execute_input":"2022-11-22T04:37:04.574445Z","iopub.status.idle":"2022-11-22T04:37:04.586938Z","shell.execute_reply.started":"2022-11-22T04:37:04.574419Z","shell.execute_reply":"2022-11-22T04:37:04.584849Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([[0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\n\n\n\nclass conv_block(tf.keras.Model):\n    def __init__(self, filters, strides=(2, 2)):\n        super(conv_block, self).__init__()\n\n        self.filters1, self.filters2, self.filters3 = filters\n        self.strides = strides\n\n        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=strides)\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.relu1 = tf.keras.layers.ReLU()\n\n        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.relu2 = tf.keras.layers.ReLU()\n\n        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))\n        self.bn3 = tf.keras.layers.BatchNormalization()\n\n        self.shortcut_conv = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=strides)\n        self.shortcut_bn = tf.keras.layers.BatchNormalization()\n\n        self.add = tf.keras.layers.Add()\n        self.add_relu = tf.keras.layers.ReLU()\n\n\n    def call(self, input_tensor, training=False):\n        x = self.conv1(input_tensor)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        shortcut = self.shortcut_conv(input_tensor)\n        shortcut = self.shortcut_bn(shortcut)\n\n        x = self.add([x, shortcut])\n        x = self.add_relu(x)\n\n        return x\n        \n\n\nclass identity_block(tf.keras.Model):\n    def __init__(self, filters):\n        super(identity_block, self).__init__()\n\n        self.filters1, self.filters2, self.filters3 = filters\n\n        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=(1, 1))\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.relu1 = tf.keras.layers.ReLU()\n\n        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.relu2 = tf.keras.layers.ReLU()\n\n        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        \n        self.add = tf.keras.layers.Add()\n        self.add_relu = tf.keras.layers.ReLU()\n\n    \n    def call(self, input_tensor, training=False):\n        x = self.conv1(input_tensor)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        x = self.add([x, input_tensor])\n        x = self.add_relu(x)\n\n        return x\n\n\n\n\n    \nclass ResNet50(tf.keras.Model):\n    def __init__(self, nb_classes):\n        super(ResNet50, self).__init__()\n\n        self.nb_classes = nb_classes\n\n        # Stage 1 (Conv1 Layer)\n        self.zero_padd_1_1 = tf.keras.layers.ZeroPadding2D(padding=(3, 3))\n        self.conv_1 = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2))\n        self.bn_1 = tf.keras.layers.BatchNormalization()\n        self.relu_1 = tf.keras.layers.ReLU()\n        self.zero_padd_1_2 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))\n        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))\n\n        # Stage 2\n        self.stage2 = tf.keras.Sequential()\n        self.stage2.add(conv_block([64, 64, 256], strides=(1, 1)))\n        self.stage2.add(identity_block([64, 64, 256]))\n        self.stage2.add(identity_block([64, 64, 256]))\n\n        # Stage 3\n        self.stage3 = tf.keras.Sequential()\n        self.stage3.add(conv_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n        self.stage3.add(identity_block([128, 128, 512]))\n\n        # Stage 4\n        self.stage4 = tf.keras.Sequential()\n        self.stage4.add(conv_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n        self.stage4.add(identity_block([256, 256, 1024]))\n\n        # Stage 5\n        self.stage5 = tf.keras.Sequential()\n        self.stage5.add(conv_block([512, 512, 2048]))\n        self.stage5.add(identity_block([512, 512, 2048]))\n        self.stage5.add(identity_block([512, 512, 2048]))\n\n\n        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n        self.dense = tf.keras.layers.Dense(self.nb_classes, activation='softmax')\n\n\n    def call(self, input_tensor, training=False):\n        x = self.zero_padd_1_1(input_tensor)\n        x = self.conv_1(x)\n        x = self.bn_1(x)\n        x = self.relu_1(x)\n        x = self.zero_padd_1_2(x)\n        x = self.max_pool(x)\n\n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.stage4(x)\n        x = self.stage5(x)\n\n        x = self.gap(x)\n        x = self.dense(x)\n\n        return x \n\n\nmodel = ResNet50(1000)\nmodel.build((1, 224, 224, 3))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:04.588315Z","iopub.execute_input":"2022-11-22T04:37:04.588848Z","iopub.status.idle":"2022-11-22T04:37:06.467825Z","shell.execute_reply.started":"2022-11-22T04:37:04.588818Z","shell.execute_reply":"2022-11-22T04:37:06.466692Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"2022-11-22 04:37:04.704062: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"res_net50\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nzero_padding2d (ZeroPadding2 multiple                  0         \n_________________________________________________________________\nconv2d (Conv2D)              multiple                  9472      \n_________________________________________________________________\nbatch_normalization (BatchNo multiple                  256       \n_________________________________________________________________\nre_lu (ReLU)                 multiple                  0         \n_________________________________________________________________\nzero_padding2d_1 (ZeroPaddin multiple                  0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) multiple                  0         \n_________________________________________________________________\nsequential (Sequential)      (1, 56, 56, 256)          220032    \n_________________________________________________________________\nsequential_1 (Sequential)    (1, 28, 28, 512)          1230336   \n_________________________________________________________________\nsequential_2 (Sequential)    (1, 14, 14, 1024)         7129088   \n_________________________________________________________________\nsequential_3 (Sequential)    (1, 7, 7, 2048)           14998528  \n_________________________________________________________________\nglobal_average_pooling2d (Gl multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  2049000   \n=================================================================\nTotal params: 25,636,712\nTrainable params: 25,583,592\nNon-trainable params: 53,120\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    loss = 'sparse_categorical_crossentropy'\n    ,metrics = ['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:06.469954Z","iopub.execute_input":"2022-11-22T04:37:06.470313Z","iopub.status.idle":"2022-11-22T04:37:06.488433Z","shell.execute_reply.started":"2022-11-22T04:37:06.470286Z","shell.execute_reply":"2022-11-22T04:37:06.486899Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nTRAIN_STEPS = len(train_df)//BATCH_SIZE\nVAL_STEPS = len(valid_df)//BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:06.490992Z","iopub.execute_input":"2022-11-22T04:37:06.491537Z","iopub.status.idle":"2022-11-22T04:37:06.499435Z","shell.execute_reply.started":"2022-11-22T04:37:06.491477Z","shell.execute_reply":"2022-11-22T04:37:06.497921Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"reduceLR = ReduceLROnPlateau(monitor='val_accuracy', patience=10, verbose= 1, mode='max', factor=  0.2, min_lr = 1e-5)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience = 20, verbose=1, mode='max', restore_best_weights= True)\n\ncheckpoint = ModelCheckpoint('movilenet_v1', monitor='val_accuracy', verbose=1,save_best_only=True, mode= 'max')","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:06.501468Z","iopub.execute_input":"2022-11-22T04:37:06.502370Z","iopub.status.idle":"2022-11-22T04:37:06.512181Z","shell.execute_reply.started":"2022-11-22T04:37:06.502340Z","shell.execute_reply":"2022-11-22T04:37:06.509821Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Non-augmentation\ntrain_gen = ImageDataGenerator().flow(X_train, y_train, batch_size = BATCH_SIZE)\nvalid_gen = ImageDataGenerator().flow(X_valid, y_valid, batch_size = BATCH_SIZE)\n\nhistory_res50 = model.fit(\n    train_gen\n    , steps_per_epoch = TRAIN_STEPS\n    , validation_data = valid_gen\n    , epochs = 20\n    , callbacks = [reduceLR, early_stopping, checkpoint]\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T04:37:06.514472Z","iopub.execute_input":"2022-11-22T04:37:06.514976Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2022-11-22 04:37:13.144424: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n410/410 [==============================] - 1663s 4s/step - loss: 1.2444 - accuracy: 0.4834 - val_loss: 9.7278 - val_accuracy: 0.4212\n\nEpoch 00001: val_accuracy improved from -inf to 0.42118, saving model to movilenet_v1\n","output_type":"stream"},{"name":"stderr","text":"2022-11-22 05:05:13.349020: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20\n410/410 [==============================] - ETA: 0s - loss: 1.0690 - accuracy: 0.4973","output_type":"stream"}]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history_mov1.history['accuracy'], label='Training Accuracy')\nplt.plot(history_mov1.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history_mov1.history['loss'], label='Training Loss')\nplt.plot(history_mov1.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255,\n                     rotation_range=20,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.1,\n                     vertical_flip=True,\n                     horizontal_flip=True,\n                     fill_mode='nearest')\n\n\ntrain_gen_ag = train_datagen.flow(X_train, y_train, batch_size = BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduceLR = ReduceLROnPlateau(monitor='val_accuracy', patience=10, verbose= 1, mode='max', factor=  0.2, min_lr = 1e-5)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience = 20, verbose=1, mode='max', restore_best_weights= True)\n\ncheckpoint_ag = ModelCheckpoint('movilenet_v1_ag', monitor='val_accuracy', verbose=1,save_best_only=True, mode= 'max')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_res50_ag = model.fit(\n    train_gen_ag\n    , steps_per_epoch= TRAIN_STEPS\n    , validation_data=valid_gen\n    , validation_steps=VAL_STEPS\n    , epochs= 20\n    , callbacks= [reduceLR, early_stopping, checkpoint_ag]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 16))\n\nplt.subplot(2, 2, 1)\nplt.plot(history_mov1.history['accuracy'], label='Training Accuracy')\nplt.plot(history_mov1.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Non-Augmentation Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(history_mov1.history['loss'], label='Training Loss')\nplt.plot(history_mov1.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Non-Augmentation Training and Validation Loss')\n\nplt.subplot(2, 2, 3)\nplt.plot(history_mov1_ag.history['accuracy'], label='Training Accuracy')\nplt.plot(history_mov1_ag.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Augmentation Training and Validation Accuracy')\n\nplt.subplot(2, 2, 4)\nplt.plot(history_mov1_ag.history['loss'], label='Training Loss')\nplt.plot(history_mov1_ag.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Augmentation Training and Validation Loss')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#이미지 오류남\n\n#stage1 = y_train[y_train == 0].index\n#stage2 = y_train[y_train == 1].index\n#stage3 = y_train[y_train == 2].index\n\n#\n\n#stage1 = np.where(y_train == 0)\n#type(stage1)\n#stageq = stage1[0]\n\n#stage2 = np.where(y_train == 1)\n#type(stage2)\n#stagew = stage2[0]\n\n#stage3 = np.where(y_train == 2)\n#type(stage3)\n#stagee = stage3[0]\n\n#\n\n#plt.figure(figsize=(20, 20))\n\n#for i in range(16):\n#    plt.subplot(4, 4, i+1)\n#    plt.suptitle('Type1 Images', fontsize=20) # 하나의 큰 제목 설정\n#    plt.imshow(X_train[stageq[i]])\n#    plt.title('Type1')\n#    plt.subplots_adjust(hspace=0.5)\n#    plt.axis(False)\n#plt.show()\n\n#\n\n#plt.figure(figsize=(20, 20))\n\n#for i in range(16):\n#    plt.subplot(4, 4, i+1)\n#    plt.suptitle('type2 Images', fontsize=20) # 하나의 큰 제목 설정\n#    plt.imshow(X_train[stagew[i]])\n#    plt.title('type2')\n#    plt.subplots_adjust(hspace=0.5)\n#    plt.axis(False)\n#plt.savefig('type2.png', dpi=300)\n#plt.show()\n\n#\n\n#plt.figure(figsize=(20, 20))\n#\n#for i in range(16):\n#    plt.subplot(4, 4, i+1)\n#    plt.suptitle('type3 Images', fontsize=20) # 하나의 큰 제목 설정\n#    plt.imshow(X_train[stagee[i]])\n#    plt.title('type3')\n#    plt.subplots_adjust(hspace=0.5)\n#    plt.axis(False)\n#plt.savefig('type3.png', dpi=300)\n#plt.show()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 참고용\n# double\n\n#history_df_cnn = pd.DataFrame(historycnn.history)\n#history_df_dnn = pd.DataFrame(historydnn.history)\n\n#plt.figure(figsize= (15,6))\n#plt.subplot(1,2,1)\n#plt.plot(history_df_cnn['accuracy'], label= 'cnn_accuracy' )\n## plt.plot(history_df_cnn['val_accuracy'], label= 'val_accuracy')\n#plt.plot(history_df_dnn['accuracy'], label= 'dnn_accuracy', color='limegreen' )\n## plt.plot(history_df_dnn['val_accuracy'], label= 'val_accuracy', color='limegreen')\n## history_df[['acc', 'val_acc']]\n#plt.xlabel('Epochs')\n#plt.ylabel('Accuracy')\n#plt.title('Training and Validation Accuracy History')\n#plt.legend()\n\n# display history of loss\n#plt.subplot(1,2,2)\n#plt.plot(history_df_cnn['loss'], label= 'cnn_loss')\n##plt.plot(history_df_cnn['val_loss'], label= 'val_loss')\n#plt.plot(history_df_dnn['loss'], label= 'dnn_loss', color='limegreen')\n##plt.plot(history_df_dnn['val_loss'], label= 'val_loss', color='limegreen')\n# history_df[['loss', 'val_loss']].plot()\n#plt.xlabel('Epochs')\n#plt.ylabel('Loss')\n#plt.title('Training and Validation Loss History')\n#plt.legend()\n#plt.savefig('fig2.png', dpi=300)\n#plt.show()\n","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize= (6,6))\n#plt.plot(history_df_cnn['accuracy'], label= 'cnn_accuracy' )\n##plt.plot(history_df_cnn['val_loss'], label= 'val_loss')\n##plt.plot(history_df_dnn['loss'], label= 'dnn_loss', color='limegreen')\n##plt.plot(history_df_dnn['val_loss'], label= 'val_loss', color='limegreen')\n## history_df[['loss', 'val_loss']].plot()\n#plt.xlabel('Epochs')\n#plt.ylabel('Loss')\n#plt.title('Training and Validation Loss History')\n#plt.legend()\n#plt.savefig('cnnaccuracy.png', dpi=300)\n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test data (2차에 활용)","metadata":{}},{"cell_type":"code","source":"# test data\n\n#test_y = pd.read_csv(\"../input/intel-mobileodt-cervical-cancer-screening/solution_stg1_release.csv\")\n#test_y.loc[1,['Type_1','Type_2','Type_3']]\n\n#root_dir = '../input/intel-mobileodt-cervical-cancer-screening'\n#test_dir = os.path.join(root_dir,'test', 'test')\n\n#test_type = []\n#test_features = []\n#i=0\n#for fn in test_y[['image_name']].to_numpy():\n#    for filename in fn:\n#        filepath = os.path.join(test_dir,filename)\n#        #print(filepath)\n#        img = cv2.imread(filepath)\n#        resized_img = cv2.resize(img, (180, 180))\n#        test_features.append(np.array(resized_img))\n#        test_type.append(np.array(test_y.loc[i,['Type_1','Type_2','Type_3']]))\n#        i=i+1\n    \n#print( len(test_features))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_y = pd.read_csv(\"../input/intel-mobileodt-cervical-cancer-screening/solution_stg1_release.csv\")\n#test_y.loc[1,['Type_1','Type_2','Type_3']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test = test_y.loc[:,['Type_1','Type_2','Type_3']]\n#y_test\n#import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_train_onehot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(y_test)\n#list = []\n#for d in y_test.index:\n#    res = y_test.loc[d,:].values.tolist()\n#    list.append(res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test = np.array(list)\n#y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize test features\n#test_X = np.array(test_features)\n#X_test = test_X/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(cnn.evaluate(X_test, y_test))\n#print(dnn.evaluate(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}